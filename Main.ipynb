{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9424bd2b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import time\n",
    "import matplotlib.pyplot as plt\n",
    "from stable_baselines3 import PPO\n",
    "from stable_baselines3.common.env_util import make_vec_env\n",
    "from stable_baselines3.common.vec_env import DummyVecEnv\n",
    "from stable_baselines3.common.callbacks import BaseCallback\n",
    "from gym import Env\n",
    "from gym.spaces import Box\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce53d6e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "class VMEnv(Env):\n",
    "    def __init__(self, df, window_size):\n",
    "        super(VMEnv, self).__init__()\n",
    "        self.df = df.reset_index(drop=True)\n",
    "        self.window_size = window_size\n",
    "        self.current_step = 0\n",
    "        for col in ['CPU_usage_MHZ', 'Memory_usage_KB', 'Network_received_throughput_KB_s']:\n",
    "            self.df[col] = pd.to_numeric(self.df[col], errors='coerce')\n",
    "        self.df = self.df.dropna(subset=['CPU_usage_MHZ', 'Memory_usage_KB', 'Network_received_throughput_KB_s'])\n",
    "        self.observation_space = Box(low=0, high=np.inf, shape=(window_size, 3), dtype=np.float32)\n",
    "        self.action_space = Box(low=-1, high=1, shape=(3,), dtype=np.float32)\n",
    "\n",
    "    def reset(self):\n",
    "        self.current_step = 0\n",
    "        return self._get_observation()\n",
    "\n",
    "    def step(self, action):\n",
    "        self.current_step += 1\n",
    "        obs = self._get_observation()\n",
    "        reward = self._get_reward(action)\n",
    "        done = self.current_step >= len(self.df) - self.window_size\n",
    "        info = {\n",
    "            'cpu_usage': float(self.df['CPU_usage_MHZ'].iloc[self.current_step]) if self.current_step < len(self.df) else 0.0,\n",
    "            'memory_usage': float(self.df['Memory_usage_KB'].iloc[self.current_step]) if self.current_step < len(self.df) else 0.0,\n",
    "            'network_received': float(self.df['Network_received_throughput_KB_s'].iloc[self.current_step]) if self.current_step < len(self.df) else 0.0\n",
    "        }\n",
    "        return obs, reward, done, info\n",
    "\n",
    "    def _get_observation(self):\n",
    "        start = max(0, self.current_step - self.window_size + 1)\n",
    "        end = min(self.current_step + 1, len(self.df))\n",
    "        window = self.df[['CPU_usage_MHZ', 'Memory_usage_KB', 'Network_received_throughput_KB_s']].iloc[start:end].values\n",
    "        if len(window) < self.window_size:\n",
    "            padding = np.zeros((self.window_size - len(window), 3), dtype=np.float32)\n",
    "            window = np.vstack([padding, window])\n",
    "        return window.astype(np.float32)\n",
    "\n",
    "    def _get_reward(self, action):\n",
    "        if self.current_step < len(self.df):\n",
    "            actual = np.array([\n",
    "                self.df['CPU_usage_MHZ'].iloc[self.current_step],\n",
    "                self.df['Memory_usage_KB'].iloc[self.current_step],\n",
    "                self.df['Network_received_throughput_KB_s'].iloc[self.current_step]\n",
    "            ], dtype=np.float32)\n",
    "            scaling_factors = np.array([1000.0, 1000.0, 1000.0])\n",
    "            actual_normalized = actual / scaling_factors\n",
    "            predicted = action\n",
    "            mse = np.mean((actual_normalized - predicted) ** 2)\n",
    "            return -mse\n",
    "        return 0.0\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13d93dcd",
   "metadata": {},
   "outputs": [],
   "source": [
    "class TrainingLoggerCallback(BaseCallback):\n",
    "    def __init__(self, verbose=0):\n",
    "        super(TrainingLoggerCallback, self).__init__(verbose)\n",
    "        self.episode_rewards = []\n",
    "        self.episode_times = []\n",
    "        self.current_episode_reward = 0\n",
    "        self.current_episode_start_time = time.time()\n",
    "        self.episode_count = 0\n",
    "\n",
    "    def _on_step(self):\n",
    "        self.current_episode_reward += self.locals['rewards'][0]\n",
    "        if self.locals['dones'][0]:\n",
    "            self.episode_count += 1\n",
    "            episode_time = time.time() - self.current_episode_start_time\n",
    "            self.episode_rewards.append(self.current_episode_reward)\n",
    "            self.episode_times.append(episode_time)\n",
    "            self.current_episode_reward = 0\n",
    "            self.current_episode_start_time = time.time()\n",
    "            if self.verbose > 0:\n",
    "                print(f\"Episode {self.episode_count}: Reward = {self.episode_rewards[-1]:.2f}, Time = {self.episode_times[-1]:.2f}s\")\n",
    "        return True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3be8bbdc",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df = pd.read_csv('train_df.csv')\n",
    "train_df['CPU_usage_MHZ'] = train_df['CPU_usage_MHZ'] * 1e6\n",
    "train_df['Memory_usage_KB'] = train_df['Memory_usage_KB'] * 1e6\n",
    "train_df['Network_received_throughput_KB_s'] = train_df['Network_received_throughput_KB_s'] * 1e6\n",
    "\n",
    "# Create environment\n",
    "window_size = 100\n",
    "env = make_vec_env(VMEnv, n_envs=1, vec_env_cls=DummyVecEnv, env_kwargs={'df': train_df, 'window_size': window_size})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "56405b07",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2905fe8d",
   "metadata": {},
   "outputs": [],
   "source": [
    "callback = TrainingLoggerCallback(verbose=1)\n",
    "model = PPO(\"MlpPolicy\", env, verbose=1, learning_rate=0.0003, n_steps=2048, batch_size=64, clip_range=0.2)\n",
    "model.learn(total_timesteps=100000, callback=callback)\n",
    "model.save(\"ppo_resource_prediction\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b7485d1c",
   "metadata": {},
   "outputs": [],
   "source": [
    "episode_rewards = callback.episode_rewards\n",
    "episode_times = callback.episode_times\n",
    "episodes = list(range(1, len(episode_rewards) + 1))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c0d3384e",
   "metadata": {},
   "outputs": [],
   "source": [
    "window_size_convergence = 10\n",
    "rolling_rewards = pd.Series(episode_rewards).rolling(window=window_size_convergence).mean().values\n",
    "convergence_metric = []\n",
    "for i in range(1, len(rolling_rewards)):\n",
    "    if i >= window_size_convergence:\n",
    "        prev_avg = rolling_rewards[i - 1]\n",
    "        curr_avg = rolling_rewards[i]\n",
    "        if prev_avg != 0:\n",
    "            perc_change = abs((curr_avg - prev_avg) / prev_avg) * 100\n",
    "            convergence_metric.append(perc_change)\n",
    "        else:\n",
    "            convergence_metric.append(np.inf)\n",
    "    else:\n",
    "        convergence_metric.append(np.inf)\n",
    "convergence_metric = convergence_metric[:len(episodes)]  # Align with episodes\n",
    "\n",
    "# Find convergence episode\n",
    "reward_threshold = 5.0  # 5% threshold\n",
    "convergence_episode = None\n",
    "for i, perc_change in enumerate(convergence_metric):\n",
    "    if i >= window_size_convergence and perc_change < reward_threshold:\n",
    "        convergence_episode = episodes[i]\n",
    "        break\n",
    "\n",
    "# Print convergence\n",
    "if convergence_episode:\n",
    "    print(f\"Model converged at episode {convergence_episode} (convergence metric < {reward_threshold}%)\")\n",
    "else:\n",
    "    print(\"Model did not converge within the training period\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "86628e87",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Plot Convergence vs Episode\n",
    "plt.figure(figsize=(10, 5))\n",
    "plt.plot(episodes, convergence_metric, label='Convergence Metric (% Change in Rolling Reward)')\n",
    "plt.axhline(y=reward_threshold, color='g', linestyle='--', label=f'Convergence Threshold ({reward_threshold}%)')\n",
    "if convergence_episode:\n",
    "    plt.axvline(x=convergence_episode, color='r', linestyle=':', label='Convergence Episode')\n",
    "plt.xlabel('Episode')\n",
    "plt.ylabel('Convergence Metric (%)')\n",
    "plt.title('Convergence vs Episode')\n",
    "plt.legend()\n",
    "plt.grid()\n",
    "plt.yscale('log')  \n",
    "\n",
    "\n",
    "plt.show()\n",
    "# Plot Reward vs Episode\n",
    "plt.figure(figsize=(10, 5))\n",
    "plt.plot(episodes, episode_rewards, label='Episode Reward')\n",
    "plt.plot(episodes, rolling_rewards, label='Rolling Average Reward (window=10)', linestyle='--')\n",
    "if convergence_episode:\n",
    "    plt.axvline(x=convergence_episode, color='r', linestyle=':', label='Convergence')\n",
    "plt.xlabel('Episode')\n",
    "plt.ylabel('Reward (-MSE)')\n",
    "plt.title('Reward vs Episode')\n",
    "plt.legend()\n",
    "plt.grid()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "828438ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "cumulative_times = np.cumsum(episode_times)\n",
    "plt.figure(figsize=(10, 5))\n",
    "plt.plot(episodes, cumulative_times, label='Cumulative Training Time')\n",
    "plt.xlabel('Episode')\n",
    "plt.ylabel('Training Time (seconds)')\n",
    "plt.title('Episode vs Training Time')\n",
    "plt.legend()\n",
    "plt.grid()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "390af095",
   "metadata": {},
   "outputs": [],
   "source": [
    "metrics_df = pd.DataFrame({\n",
    "    'Episode': episodes,\n",
    "    'Reward': episode_rewards,\n",
    "    'Training_Time': episode_times,\n",
    "    'Cumulative_Training_Time': cumulative_times,\n",
    "    'Convergence_Metric_Percent': convergence_metric\n",
    "})\n",
    "metrics_df.to_csv('training_metrics.csv', index=False)\n",
    "print(\"Training metrics saved to 'training_metrics.csv'\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "04d79f46",
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv\n",
    "import os\n",
    "import numpy as np\n",
    "from datetime import datetime\n",
    "from stable_baselines3 import PPO\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "719ec69c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_and_store_rl(time_str, model_path=\"ppo_resource_prediction_new.zip\", output_file=\"predictions.csv\", window_size=100, test_df_path=\"test_df.csv\"):\n",
    "    \n",
    "    # Validate and parse time string\n",
    "    try:\n",
    "        time_obj = datetime.strptime(time_str, \"%H:%M:%S\")\n",
    "    except ValueError:\n",
    "        raise ValueError(\"Time must be in HH:MM:SS format (e.g., '12:34:56')\")\n",
    "    \n",
    "    # Load and scale test data\n",
    "    test_df = pd.read_csv(test_df_path)\n",
    "    test_df['CPU_usage_MHZ'] = test_df['CPU_usage_MHZ'] * 1e6\n",
    "    test_df['Memory_usage_KB'] = test_df['Memory_usage_KB'] * 1e6\n",
    "    test_df['Network_received_throughput_KB_s'] = test_df['Network_received_throughput_KB_s'] * 1e6\n",
    "    \n",
    "    # Filter test data by time (approximate match)\n",
    "    test_df['time'] = pd.to_datetime(test_df['time'], format='%H:%M:%S.%f')\n",
    "    time_seconds = time_obj.hour * 3600 + time_obj.minute * 60 + time_obj.second\n",
    "    test_df['time_seconds'] = test_df['time'].dt.hour * 3600 + test_df['time'].dt.minute * 60 + test_df['time'].dt.second\n",
    "    time_diff = np.abs(test_df['time_seconds'] - time_seconds)\n",
    "    closest_rows = test_df.iloc[time_diff.argsort()[:window_size]]\n",
    "    \n",
    "    # Create observation\n",
    "    observation = closest_rows[['CPU_usage_MHZ', 'Memory_usage_KB', 'Network_received_throughput_KB_s']].values.astype(np.float32)\n",
    "    if len(observation) < window_size:\n",
    "        padding = np.zeros((window_size - len(observation), 3), dtype=np.float32)\n",
    "        observation = np.vstack([padding, observation])\n",
    "    assert observation.shape == (window_size, 3), f\"Observation shape {observation.shape} does not match expected ({window_size}, 3)\"\n",
    "    \n",
    "    # Load the trained PPO model\n",
    "    try:\n",
    "        model = PPO.load(model_path)\n",
    "    except Exception as e:\n",
    "        raise ValueError(f\"Failed to load PPO model from {model_path}: {str(e)}\")\n",
    "    \n",
    "    # Predict using the PPO model\n",
    "    try:\n",
    "        action, _ = model.predict(observation, deterministic=True)\n",
    "    except Exception as e:\n",
    "        raise ValueError(f\"Prediction failed: {str(e)}\")\n",
    "    \n",
    "    # Action is a 3D vector [cpu_adjustment, mem_adjustment, net_adjustment]\n",
    "    assert action.shape == (3,), f\"Action shape {action.shape} does not match expected (3,)\"\n",
    "    \n",
    "    # Scale actions to resource values\n",
    "    scaling_factors = np.array([1000.0, 1000.0, 1000.0])  # Match VMEnv reward scaling\n",
    "    predicted = action * scaling_factors\n",
    "    predicted_cpu, predicted_mem, predicted_net = predicted\n",
    "    \n",
    "    # Ensure predictions are within bounds\n",
    "    predicted_cpu = max(0, min(predicted_cpu, 5000))\n",
    "    predicted_mem = max(0, min(predicted_mem, 10000))\n",
    "    predicted_net = max(0, min(predicted_net, 2000))\n",
    "    \n",
    "    # Round predictions\n",
    "    predicted_cpu = round(predicted_cpu, 2)\n",
    "    predicted_mem = round(predicted_mem, 2)\n",
    "    predicted_net = round(predicted_net, 2)\n",
    "    \n",
    "    # Calculate VMs needed\n",
    "    vms_needed = int(np.ceil(predicted_cpu / 500))\n",
    "    \n",
    "    # Prepare data to store\n",
    "    prediction_data = {\n",
    "        \"Time\": time_str,\n",
    "        \"CPU_usage_MHZ\": predicted_cpu,\n",
    "        \"Memory_usage_KB\": predicted_mem,\n",
    "        \"Network_received_throughput_KB_s\": predicted_net,\n",
    "        \"VMs_needed\": vms_needed\n",
    "    }\n",
    "    \n",
    "    # Store predictions in CSV\n",
    "    file_exists = os.path.exists(output_file)\n",
    "    with open(output_file, mode='a', newline='') as file:\n",
    "        writer = csv.DictWriter(file, fieldnames=prediction_data.keys())\n",
    "        if not file_exists:\n",
    "            writer.writeheader()\n",
    "        writer.writerow(prediction_data)\n",
    "    \n",
    "    print(f\"Stored predictions for {time_str} in {output_file}\")\n",
    "    return prediction_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "89a7191c",
   "metadata": {},
   "outputs": [],
   "source": [
    "another_time = \"22:18:35\"\n",
    "result = predict_and_store_rl(another_time, model_path=\"ppo_resource_prediction.zip\")\n",
    "print(\"Predictions:\", result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5433c836",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e429f03",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b091235",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
